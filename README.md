# EcgArrhythmiaDetection ü´Ä

## Resumen de conceptos üß†

### Redes Neuronales Artificiales (RNA) üîÆ  
Una Red Neuronal Artificial es un modelo computacional inspirado en la estructura y funciones de las neuronas biol√≥gicas, compuesto por capas de nodos (neuronas artificiales) que transfieren informaci√≥n mediante conexiones ponderadas. Cada neurona recibe se√±ales de entrada, las combina linealmente, aplica una funci√≥n de activaci√≥n no lineal (por ejemplo ReLU) y transmite su salida a la siguiente capa. Las RNA feed-forward (o perceptr√≥n multicapa) se emplean para clasificaci√≥n y regresi√≥n cuando los datos no tienen componentes espaciales o temporales expl√≠citos.

### Redes Neuronales Convolucionales (CNN) üëÅÔ∏è  
Las CNN son un tipo de RNA feed-forward optimizadas para datos con estructura espacial (im√°genes o se√±ales), usando **filtros convolucionales** que aprenden patrones locales mediante operaciones de convoluci√≥n. Cada capa convolucional extrae mapas de caracter√≠sticas, seguidos por capas de **pooling** que reducen la dimensionalidad y **Batch Normalization** para estabilizar el entrenamiento. Dropout se a√±ade para mitigar el sobreajuste, y finalmente una capa densa con softmax genera la distribuci√≥n de probabilidad sobre las clases.

### Redes Neuronales Recurrentes (RNN) ‚è±Ô∏è  
Las RNN est√°n dise√±adas para datos secuenciales o series de tiempo, alimentando la salida de una neurona como entrada en pasos posteriores, lo que permite modelar dependencias temporales. Las variantes LSTM y GRU incorporan **mecanismos de puerta** para conservar informaci√≥n relevante por m√°s pasos y evitar problemas de gradientes desaparecidos o explosivos.

## Enunciado del problema ‚ùó

Las **enfermedades cardiovasculares (CVD)** son la principal causa de muerte global, con 17.9 millones de fallecimientos en 2019 (32 % de todas las muertes) seg√∫n la OMS, y gran parte de ellas prevenibles si se detectan a tiempo. El objetivo es desarrollar modelos autom√°ticos que clasifiquen se√±ales de ECG de la base MIT-BIH Arrhythmia Database (48 grabaciones de 30 min, dos canales) para identificar distintos tipos de arritmias, mejorando la detecci√≥n temprana y facilitando aplicaciones de telemedicina.

## C√≥digo üíª

<details>
<summary>1. Preprocesamiento de datos üîç</summary>

Carga, normalizaci√≥n, balanceo y preparaci√≥n de datos para los modelos.

```python
# data_processing.py

def load_data():
    train_df = pd.read_csv(TRAIN_FILE, header=None)
    test_df  = pd.read_csv(TEST_FILE,  header=None)
    return train_df, test_df

def preprocess(df):
    X = df.iloc[:, :187].astype(np.float32)      # 187 muestras temporales
    y = df.iloc[:, 187].astype(int)               # etiqueta (0‚Äì4)
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)            # normalizaci√≥n Z-score
    return X_scaled, y, scaler

# reshape para modelos 1D: (samples, timesteps, 1)
X_train = X_train.reshape(-1, 187, 1)
```
</details>

<details>
<summary>2. Definici√≥n de arquitecturas üèóÔ∏è</summary>

### RNA (Artificial Neural Network)
Capas densas y Dropout para extraer caracter√≠sticas globales.

```python
# models/ann.py

def build_ann(input_shape, hidden_sizes, dropout_rates):
    model = Sequential([Flatten(input_shape=input_shape)])
    for nh, dr in zip(hidden_sizes, dropout_rates):
        model.add(Dense(nh, activation='relu'))
        model.add(Dropout(dr))
    model.add(Dense(num_clases, activation='softmax'))
    model.compile(optimizer=Adam(lr), loss='categorical_crossentropy', metrics=['accuracy'])
    return model
```

### CNN (Convolutional Neural Network) 
Bloques Conv1D + BatchNorm + MaxPooling + Dropout.

```python
# models/cnn.py

def build_cnn(input_shape, filters, dropout_rates):
    model = Sequential()
    for i, (f, dr) in enumerate(zip(filters, dropout_rates)):
        if i == 0:
            model.add(Conv1D(f, kernel_size=5, activation='relu', input_shape=input_shape))
        else:
            model.add(Conv1D(f, 5, activation='relu'))
        model.add(BatchNormalization())
        model.add(MaxPooling1D(2))
        model.add(Dropout(dr))
    model.add(Flatten())
    model.add(Dense(64, activation='relu'))
    model.add(Dropout(0.5))
    model.add(Dense(num_clases, activation='softmax'))
    model.compile(optimizer=Adam(lr), loss='categorical_crossentropy', metrics=['accuracy'])
    return model
```

### RNN (LSTM)
Capas LSTM con `return_sequences` y Dropout.

```python
# models/rnn.py

def build_rnn(input_shape, units, dropout_rates):
    model = Sequential()
    for i, (u, dr) in enumerate(zip(units, dropout_rates)):
        rs = (i < len(units)-1)
        if i == 0:
            model.add(LSTM(u, return_sequences=rs, input_shape=input_shape))
        else:
            model.add(LSTM(u, return_sequences=rs))
        model.add(Dropout(dr))
    model.add(Dense(num_clases, activation='softmax'))
    model.compile(optimizer=Adam(lr), loss='categorical_crossentropy', metrics=['accuracy'])
    return model
```
</details>

<details>
<summary>3. Entrenamiento y guardado üéØ</summary>

Generaci√≥n de nombre √∫nico para cada experimento, entrenamiento con EarlyStopping y guardado del mejor modelo.

```python
# train.py

# Generar nombre corto seg√∫n par√°metros
def make_run_name(args):
    lr_str = f"{args.learning_rate:.0e}"
    parts = [args.model, f"e{args.epochs}", f"bs{args.batch_size}", f"lr{lr_str}"]
    # anexar hidden_sizes/filters/units y dropout
    ...
    return "_".join(parts)

# Callbacks: EarlyStopping, ReduceLROnPlateau, ModelCheckpoint
callbacks = [
    EarlyStopping(patience=5, restore_best_weights=True),
    ReduceLROnPlateau(patience=3),
    ModelCheckpoint("temp_best.h5", save_best_only=True)
]

history = model.fit(X_train, y_train,
                    validation_data=(X_val, y_val),
                    epochs=args.epochs,
                    batch_size=args.batch_size,
                    callbacks=callbacks)

# Renombra y mueve al directorio de modelos
run_name = make_run_name(args)
os.replace("temp_best.h5", f"models/saved/{run_name}.h5")
```
</details>

<details>
<summary>4. Evaluaci√≥n y m√©tricas üìä</summary>

C√°lculo y exportaci√≥n de m√©tricas de evaluaci√≥n: p√©rdida y precisi√≥n en test, reporte de clasificaci√≥n y matriz de confusi√≥n.

```python
# evaluate.py

# 1) M√©tricas globales
loss, acc = model.evaluate(X_test, y_test, verbose=0)
pd.DataFrame([{'test_loss': loss, 'test_accuracy': acc}]).to_csv(f"{run}/test_metrics.csv", index=False)

# 2) Reporte detallado
cr = classification_report(y_true, y_pred, target_names=LABELS, output_dict=True)
pd.DataFrame(cr).transpose().to_csv(f"{run}/classification_report.csv")

# 3) Matriz de confusi√≥n
evaluate_model(model, X_test, y_test, run_name, plots_dir=f"{run}/plots")
```
</details>

## Resultados üìà

**Curvas de entrenamiento y p√©rdida** üìâ  
ANN:  
![Accuracy ANN](results/ann_e100_bs128_lr5e-04_h256-128-64_d0p5-0p5-0p5/plots/ann_e100_bs128_lr5e-04_h256-128-64_d0p5-0p5-0p5_accuracy.png)  
![Loss ANN](results/ann_e100_bs128_lr5e-04_h256-128-64_d0p5-0p5-0p5/plots/ann_e100_bs128_lr5e-04_h256-128-64_d0p5-0p5-0p5_loss.png)

CNN:  
![Accuracy CNN](results/cnn_e100_bs128_lr1e-03_f32-64-128-256_d0p3-0p3-0p3-0p4/plots/cnn_e100_bs128_lr1e-03_f32-64-128-256_d0p3-0p3-0p3-0p4_accuracy.png)  
![Loss CNN](results/cnn_e100_bs128_lr1e-03_f32-64-128-256_d0p3-0p3-0p3-0p4/plots/cnn_e100_bs128_lr1e-03_f32-64-128-256_d0p3-0p3-0p3-0p4_loss.png)  

RNN:  
![Accuracy RNN](results/rnn_e100_bs64_lr1e-03_u128-64_d0p3-0p3/plots/rnn_e100_bs64_lr1e-03_u128-64_d0p3-0p3_accuracy.png)  
![Loss RNN](results/rnn_e100_bs64_lr1e-03_u128-64_d0p3-0p3/plots/rnn_e100_bs64_lr1e-03_u128-64_d0p3-0p3_loss.png)  

**Matriz de confusi√≥n** üéØ  
ANN:  
![Confusi√≥n ANN](results/ann_e100_bs128_lr5e-04_h256-128-64_d0p5-0p5-0p5/plots/ann_e100_bs128_lr5e-04_h256-128-64_d0p5-0p5-0p5_confusion_matrix.png)  
CNN:  
![Confusi√≥n CNN](results/cnn_e100_bs128_lr1e-03_f32-64-128-256_d0p3-0p3-0p3-0p4/plots/cnn_e100_bs128_lr1e-03_f32-64-128-256_d0p3-0p3-0p3-0p4_confusion_matrix.png)  
RNN:  
![Confusi√≥n RNN](results/rnn_e100_bs64_lr1e-03_u128-64_d0p3-0p3/plots/rnn_e100_bs64_lr1e-03_u128-64_d0p3-0p3_confusion_matrix.png)  

**Tabla de hiperpar√°metros y m√©tricas** üìã  

| Modelo | Epochs | Batch Size | Learning Rate | Estructura (capas/filtros/unidades) | Dropout Rates | Val Accuracy | Val Loss | Test Accuracy | Test Loss |
|--------|--------|------------|---------------|-------------------------------------|---------------|--------------|----------|---------------|-----------|
| ANN    | 100    | 128        | 5e-4          | 256,128,64                          | 0.5,0.5,0.5   | 0.992        | 0.027    | 0.971         | 0.113     |
| CNN    | 100    | 128        | 1e-3          | 32,64,128,256                       | 0.3,0.3,0.3,0.4| 0.994        | 0.018    | 0.976         | 0.095     |
| RNN    | 100    | 64         | 1e-3          | 128,64                              | 0.3,0.3       | 0.998        | 0.012    | 0.983         | 0.115     |

**Reporte de clasificaci√≥n ANN**  

| Clase                          | Precision | Recall | F1-Score | Soporte |
|--------------------------------|-----------|--------|----------|---------|
| Normal                        | 0.991     | 0.977  | 0.984    | 18118   |
| Artial Premature              | 0.629     | 0.815  | 0.710    | 556     |
| Premature ventricular contraction | 0.905 | 0.963  | 0.933    | 1448    |
| Fusion of ventricular and normal | 0.775   | 0.809  | 0.792    | 162     |
| Fusion of paced and normal    | 0.986     | 0.984  | 0.985    | 1608    |
| **Macro avg**                 | 0.857     | 0.909  | 0.881    | 21892   |
| **Weighted avg**              | 0.974     | 0.971  | 0.972    | 21892   |

**Reporte de clasificaci√≥n CNN**  

| Clase                          | Precision | Recall | F1-Score | Soporte |
|--------------------------------|-----------|--------|----------|---------|
| Normal                        | 0.996     | 0.979  | 0.987    | 18118   |
| Artial Premature              | 0.688     | 0.901  | 0.780    | 556     |
| Premature ventricular contraction | 0.949 | 0.956  | 0.953    | 1448    |
| Fusion of ventricular and normal | 0.530   | 0.870  | 0.659    | 162     |
| Fusion of paced and normal    | 0.985     | 0.996  | 0.990    | 1608    |
| **Macro avg**                 | 0.830     | 0.940  | 0.874    | 21892   |
| **Weighted avg**              | 0.980     | 0.976  | 0.977    | 21892   |

**Reporte de clasificaci√≥n RNN**  

| Clase                          | Precision | Recall | F1-Score | Soporte |
|--------------------------------|-----------|--------|----------|---------|
| Normal                        | 0.992     | 0.991  | 0.991    | 18118   |
| Artial Premature              | 0.814     | 0.840  | 0.827    | 556     |
| Premature ventricular contraction | 0.958 | 0.956  | 0.957    | 1448    |
| Fusion of ventricular and normal | 0.813   | 0.802  | 0.807    | 162     |
| Fusion of paced and normal    | 0.991     | 0.987  | 0.989    | 1608    |
| **Macro avg**                 | 0.913     | 0.915  | 0.914    | 21892   |
| **Weighted avg**              | 0.984     | 0.983  | 0.983    | 21892   |

## Comparaci√≥n de los tres clasificadores üîç

A continuaci√≥n se presenta un an√°lisis comparativo de los tres modelos implementados (ANN, CNN y RNN) utilizando las m√©tricas de validaci√≥n y test accuracy, recall y F1-score. Los resultados se basan en los experimentos realizados sobre el dataset MIT-BIH Arrhythmia:

| Modelo | Val Accuracy | Test Accuracy | Macro Recall | Macro F1-score |
|--------|--------------|---------------|--------------|----------------|
| ANN    | 0.992        | 0.971         | 0.909        | 0.881          |
| CNN    | 0.994        | 0.976         | 0.940        | 0.874          |
| RNN    | 0.998        | 0.983         | 0.915        | 0.914          |

- **CNN** obtuvo el mejor desempe√±o general en validaci√≥n, pero RNN logr√≥ la mayor precisi√≥n en test.
- **RNN** (LSTM) mostr√≥ un excelente rendimiento en la modelizaci√≥n de dependencias temporales, con m√©tricas muy competitivas.
- **ANN** logr√≥ resultados s√≥lidos, aunque ligeramente inferiores, siendo m√°s sensible a la selecci√≥n de hiperpar√°metros y al preprocesamiento.

El an√°lisis detallado de los reportes de clasificaci√≥n muestra que tanto CNN como RNN presentan mayor recall y F1-score en las clases minoritarias respecto a ANN, lo que indica mejor capacidad de generalizaci√≥n ante el desbalance de clases.

## Conclusiones y observaciones üéØ

- **Desempe√±o relativo** üìà: RNN es el modelo m√°s robusto para la tarea, seguido de cerca por CNN. ANN es m√°s simple y r√°pido de entrenar, pero menos eficaz ante la complejidad de las se√±ales ECG.
- **Limitaciones** ‚ö†Ô∏è: Se observa cierto desbalance en la clasificaci√≥n de clases poco representadas, lo que sugiere la necesidad de t√©cnicas adicionales como data augmentation o ajuste de pesos de clase.
- **Propuestas de mejora** üöÄ:
  - üîÑ Explorar arquitecturas h√≠bridas (por ejemplo, CNN+RNN) para aprovechar tanto la extracci√≥n local de caracter√≠sticas como la modelizaci√≥n temporal.
  - ‚ö° Ajustar la ventana temporal de entrada y experimentar con mecanismos de atenci√≥n.
  - üéØ Implementar estrategias de regularizaci√≥n y validaci√≥n cruzada para mejorar la generalizaci√≥n.
  - üîç Investigar el impacto de diferentes t√©cnicas de preprocesamiento y normalizaci√≥n.

Estos resultados demuestran el potencial de las redes neuronales profundas para la detecci√≥n autom√°tica de arritmias en se√±ales ECG, facilitando aplicaciones de telemedicina y diagn√≥stico asistido. üè•

## Referencias üìö

1. Neural network (machine learning) ‚Äì Wikipedia 
2. What Is a Neural Network? ‚Äì Investopedia 
3. Convolutional neural network ‚Äì Wikipedia  
4. Convolutional layer ‚Äì Wikipedia 
5. Recurrent neural network ‚Äì Wikipedia 
6. RNN (software) ‚Äì Wikipedia 
7. MIT-BIH Arrhythmia Database ‚Äì PhysioNet 
8. Cardiovascular diseases (CVDs) ‚Äì WHO Fact Sheet 
9. What is Accuracy, Precision, Recall and F1 Score? ‚Äì Labelf AI
10. Accuracy vs. precision vs. recall in machine learning ‚Äì Evidently AI
